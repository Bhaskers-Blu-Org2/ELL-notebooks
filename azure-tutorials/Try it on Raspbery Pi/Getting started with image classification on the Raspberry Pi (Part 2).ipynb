{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This second part of the tutorial needs to be run on your local laptop or desktop machine. First, make sure you are running Jupyter on your laptop or desktop. Then, click the Download button above and save the .ipynb file to your Jupyter startup folder. After the download completes, the notebook will show up in the Jupyter Dashboard. Open the downloaded notebook from the Dashboard and carry on with the tutorial steps in that copy of the notebook. (You can run this tutorial in Azure, but the final steps will fail with a Timeout Error because the Raspberry Pi device cannot be reached on the network.)*\n",
    "\n",
    "The first few steps of this tutorial are repeated from Part 1. Just like the beginning of that tutorial, we choose a pre-trained model and download it (this time to your laptop or desktop machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda config --prepend channels conda-forge --prepend channels microsoft-ell\n",
    "!conda install -y ell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ell.util.gallery import ModelGallery\n",
    "gallery = ModelGallery()\n",
    "gallery.choose_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_model = gallery.model\n",
    "pretrained_model.download('getting-started', rename='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you like, you can repeat the last steps of Part 1 to build the model on the host machine and try it to make predictions on that machine. Here, let's look at building the model for the Rapsberry Pi and making predictions on that device.\n",
    "\n",
    "## Compile the model for the Raspberry Pi\n",
    "\n",
    "We are ready to cross-compile the model for deployment on the Raspberry Pi. Use the `compile` method and specify the target platform as `PI3`. This tells the ELL compiler to generate machine code for the Raspberry Pi's ARM Cortex A53 processor. The `compile` method creates a new directory named `pi3`, which contains a CMake project that can be used to build the desired Python module. This time, we need to build this project on the Raspberry Pi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ell.platform\n",
    "pretrained_model.compile(ell.platform.PI3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write code to invoke the model on the Raspberry Pi\n",
    "\n",
    "Deploy the model to the Raspberry Pi and try it out by using the Jupyter \"magic\" called `%%rpi`. This magic requires several arguments: The name of the user on the Raspberry Pi (typically \"pi\"), the Pi's IP address on the local network, the directory where the model will be downloaded, and the Python variable that refers to our model. **Change the `ip` and `user` arguments to your Raspberry Pi's IP address and your user name before running the code in the cell below.**\n",
    "\n",
    "Running this cell does several things. First, it prompts for the user password on the Pi. (This password is remembered during a notebook session, so it only needs to be entered once.) Second, it downloads the code from the local `pi3` directory to the directory on the Pi specified by `rpipath`. Next, it builds the CMake project on the Pi. (Again, this is only necessary once per model.) Finally, it runs the cell's Python code on the Pi. Any output that the Python code prints will be shown in the notebook. Also, because the Python code could contain a loop, we provide a button to allow you to stop the code running on the Pi.\n",
    "\n",
    "Just like in Part 1, start by downloading a known image and run the model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%rpi --user=pi --ip=157.54.152.78 --rpipath=/home/pi/mymodel --model=pretrained_model\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tutorialHelpers as helpers\n",
    "import sys\n",
    "sys.path.append('build')\n",
    "import model\n",
    "\n",
    "urllib.request.urlretrieve('https://microsoft.github.io/ELL/tutorials/shared/coffeemug.jpg', 'coffeemug.jpg')\n",
    "image = cv2.imread(\"coffeemug.jpg\")\n",
    "\n",
    "inputShape = model.get_default_input_shape()\n",
    "outputShape = model.get_default_output_shape()\n",
    "predictions = model.FloatVector(outputShape.Size())\n",
    "\n",
    "categories = [line.strip('\\n') for line in open('categories.txt', 'r').readlines()]\n",
    "\n",
    "input = helpers.prepare_image_for_model(image, inputShape.columns, inputShape.rows)\n",
    "model.predict(input, predictions)\n",
    "top5 = helpers.get_top_n_predictions(predictions, 5)\n",
    "text = \"\".join([\"(\" + str(int(conf * 100)) + \"%) \" + categories[index] for (index, conf) in top5])\n",
    "print('TOP 5:')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing it work on a static image, run the cell below to classify an object in a web cam image. This code works like a camera: when you run the cell, it causes the Pi to take a web cam image and runs that image through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%rpi --user=pi --ip=157.54.152.78 --rpipath=/home/pi/mymodel --model=pretrained_model\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tutorialHelpers as helpers\n",
    "import sys\n",
    "sys.path.append('build')\n",
    "import model\n",
    "\n",
    "def get_image_from_camera(camera):\n",
    "    if camera is not None:\n",
    "        # if predictor is too slow frames get buffered, this is designed to flush that buffer\n",
    "        ret, frame = camera.read()\n",
    "        if (not ret):\n",
    "            raise Exception('your capture device is not returning images')\n",
    "        return frame\n",
    "    return None\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "image = get_image_from_camera(camera)\n",
    "\n",
    "inputShape = model.get_default_input_shape()\n",
    "outputShape = model.get_default_output_shape()\n",
    "predictions = model.FloatVector(outputShape.Size())\n",
    "\n",
    "categories = [line.strip('\\n') for line in open('categories.txt', 'r').readlines()]\n",
    "\n",
    "input = helpers.prepare_image_for_model(image, inputShape.columns, inputShape.rows)\n",
    "model.predict(input, predictions)\n",
    "top5 = helpers.get_top_n_predictions(predictions, 5)\n",
    "text = \"\".join([\"(\" + str(int(conf * 100)) + \"%) \" + categories[index] for (index, conf) in top5])\n",
    "print('TOP 5:')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can also add a loop around this code to classify one web cam image after another. To stop the code from running on the Pi, click the Stop button that appears."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
